{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:34:51.199453800Z",
     "start_time": "2024-11-07T19:34:51.197472300Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, T5Tokenizer, PreTrainedTokenizerFast, convert_slow_tokenizer\n",
    "from datasets import load_dataset\n",
    "from utils import preprocess_function, parse_sql_to_canonical, tokenize\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b21fc68cd6c30d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:35:00.331141100Z",
     "start_time": "2024-11-07T19:34:59.527861Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Path to checkpoint folder\n",
    "checkpoint_path = \"../models/2_heads_2e-4_lr_constant_512MappingTokenizer_128_bs_32_dff_1\"\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2005d23-50e7-4cbb-b247-c0e6b5c58049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=convert_slow_tokenizer.convert_slow_tokenizer(T5Tokenizer(\"tokenizers/sp_512_bpe_encoded.model\", legacy=False, load_from_cache_file=False)))\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72785623-0baa-4732-b94f-3de6bec77c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/wikisql'\n",
    "dataset = load_dataset(path+'/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1534411-afc0-403a-8f89-dc0972d192d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['phase', 'question', 'table', 'sql'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "index = 42  # TODO find smart way to choose random samples\n",
    "sample = dataset[\"test\"].select(range(index, index+1))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5dc03c7b-e36b-44ad-ad07-cf216643ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# alternatively overwrite question here if people want to try custom questions on the same table\n",
    "# display table\n",
    "# sample.question[0] = \"Custom question about the same table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb9e12f2-b917-40da-8e4f-74cc7e4bf69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the premium associated with tariff code g9?[SEP]Scheme[SEP]Tariff code[SEP]BTs retail price (regulated)[SEP]Approx premium[SEP]Prefixes']\n",
      "['SELECT Approx premium FROM table WHERE Tariff code = g9']\n"
     ]
    }
   ],
   "source": [
    "preprocessed_sample = sample.map(preprocess_function, batched=True) # concatenates questions with headers using custom [SEP] token\n",
    "print(preprocessed_sample[\"input_text\"])\n",
    "print(preprocessed_sample[\"label_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e76b211e-0830-42f1-9f54-931f0b2e5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode rare tokens because the tokenizer doesn't know them\n",
    "mapping_file_path = 'mapping.json'\n",
    "reverse_mapping_file_path = 'reverse_mapping.json'\n",
    "\n",
    "with open(mapping_file_path, 'r', encoding='utf-8') as mapping_file:\n",
    "    mapping = json.load(mapping_file)\n",
    "\n",
    "with open(reverse_mapping_file_path, 'r', encoding='utf-8') as reverse_mapping_file:\n",
    "    reverse_mapping = json.load(reverse_mapping_file)\n",
    "\n",
    "encoded_preprocessed_sample = preprocessed_sample.map(lambda sample: encode_rare_chars(sample, mapping), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60c5c36a-8f23-4501-b540-79c7286aa478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c5600d6ed044bd871b6c8e45f84db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64, 57, 21, 61, 73, 345, 338, 104, 332, 157, 131, 338, 50, 346, 170, 6, 24, 235, 359, 69, 219, 127, 375, 372, 3, 351, 344, 16, 345, 333, 3, 353, 24, 235, 359, 69, 219, 3, 389, 353, 340, 204, 335, 334, 102, 61, 339, 55, 333, 66, 73, 355, 105, 50, 346, 379, 3, 366, 111, 308, 395, 61, 73, 345, 338, 104, 3, 370, 73, 359, 338, 395, 44, 2, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511]]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sample = encoded_preprocessed_sample.map(lambda sample: tokenize(sample, tokenizer), batched=True)\n",
    "print(tokenized_sample[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7657feba1bd54b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:35:02.922098Z",
     "start_time": "2024-11-07T19:35:02.919096500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def inference(input_ids) -> str:\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        outputs = model.generate(input_ids=torch.tensor(input_ids), num_beams=10, max_length=128)\n",
    "    output = tokenizer.decode(token_ids=outputs[0][1:], skip_special_tokens=True) # for some reason the beginning of sentence token doesn't get removed properly so we cut it off manually\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba6b9730-f9e0-4d15-a679-0615ba11c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(query, table_header, reverse_mapping):\n",
    "    cleaned_canonical = parse_sql_to_canonical(query, table_header, reverse_mapping)\n",
    "    cleaned_query = None\n",
    "    # cleaned_query = make_canonical_human_readable  TODO (we need this function; remove line above after wards)\n",
    "    return cleaned_canonical, cleaned_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1c618cf85c52fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:35:36.281157900Z",
     "start_time": "2024-11-07T19:35:34.837235100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: None\n",
      "Correct query: SELECT Approx premium FROM table WHERE Tariff code = g9\n",
      "Query result: \n",
      "Correct query: \n"
     ]
    }
   ],
   "source": [
    "canonical, human_readable = post_processing(inference(tokenized_sample[\"input_ids\"]), sample[\"table\"][0][\"header\"], reverse_mapping)\n",
    "print(f\"Model output: {human_readable}\")\n",
    "print(f\"Correct query: {sample[\"sql\"][0][\"human_readable\"]}\")\n",
    "\n",
    "# TODO run canonical result and solution on database to see if it works\n",
    "print(f\"Query result: \")\n",
    "print(f\"Correct query: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c5437-8a0b-4ec7-a975-b9f70d650e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286b78d-6890-44ce-8d48-11ccc71390b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
