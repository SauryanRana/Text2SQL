{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:34:51.199453800Z",
     "start_time": "2024-11-07T19:34:51.197472300Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, T5Tokenizer, PreTrainedTokenizerFast, convert_slow_tokenizer\n",
    "from datasets import load_dataset\n",
    "from utils import preprocess_function, parse_sql_to_canonical, tokenize, encode_rare_chars\n",
    "import torch\n",
    "import json\n",
    "from lib.dbengine import DBEngine\n",
    "from lib.query import Query\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21fc68cd6c30d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:35:00.331141100Z",
     "start_time": "2024-11-07T19:34:59.527861Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Path to checkpoint folder\n",
    "checkpoint_path = \"../models/4_heads_2e-4_lr_constant_512MappingTokenizer_128_bs_64_dff_32_kv_128d_1\"\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2005d23-50e7-4cbb-b247-c0e6b5c58049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=convert_slow_tokenizer.convert_slow_tokenizer(T5Tokenizer(\"tokenizers/sp_512_bpe_encoded.model\", legacy=False, load_from_cache_file=False)))\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72785623-0baa-4732-b94f-3de6bec77c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/wikisql'\n",
    "dataset = load_dataset(path+'/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1534411-afc0-403a-8f89-dc0972d192d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['phase', 'question', 'table', 'sql'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "index = 42  # TODO find smart way to choose random samples\n",
    "sample = dataset[\"test\"].select(range(index, index+1))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc03c7b-e36b-44ad-ad07-cf216643ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# alternatively overwrite question here if people want to try custom questions on the same table\n",
    "# display table\n",
    "# sample.question[0] = \"Custom question about the same table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9e12f2-b917-40da-8e4f-74cc7e4bf69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the premium associated with tariff code g9?[SEP]Scheme[SEP]Tariff code[SEP]BTs retail price (regulated)[SEP]Approx premium[SEP]Prefixes']\n",
      "['SELECT Approx premium FROM table WHERE Tariff code = g9']\n"
     ]
    }
   ],
   "source": [
    "preprocessed_sample = sample.map(preprocess_function, batched=True) # concatenates questions with headers using custom [SEP] token\n",
    "print(preprocessed_sample[\"input_text\"])\n",
    "print(preprocessed_sample[\"label_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76b211e-0830-42f1-9f54-931f0b2e5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode rare tokens because the tokenizer doesn't know them\n",
    "mapping_file_path = 'mapping.json'\n",
    "reverse_mapping_file_path = 'reverse_mapping.json'\n",
    "\n",
    "with open(mapping_file_path, 'r', encoding='utf-8') as mapping_file:\n",
    "    mapping = json.load(mapping_file)\n",
    "\n",
    "with open(reverse_mapping_file_path, 'r', encoding='utf-8') as reverse_mapping_file:\n",
    "    reverse_mapping = json.load(reverse_mapping_file)\n",
    "\n",
    "encoded_preprocessed_sample = preprocessed_sample.map(lambda sample: encode_rare_chars(sample, mapping), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c5c36a-8f23-4501-b540-79c7286aa478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64, 57, 21, 61, 73, 345, 338, 104, 332, 157, 131, 338, 50, 346, 170, 6, 24, 235, 359, 69, 219, 127, 375, 372, 3, 351, 344, 16, 345, 333, 3, 353, 24, 235, 359, 69, 219, 3, 389, 353, 340, 204, 335, 334, 102, 61, 339, 55, 333, 66, 73, 355, 105, 50, 346, 379, 3, 366, 111, 308, 395, 61, 73, 345, 338, 104, 3, 370, 73, 359, 338, 395, 44, 2, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511, 511]]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sample = encoded_preprocessed_sample.map(lambda sample: tokenize(sample, tokenizer), batched=True)\n",
    "print(tokenized_sample[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7657feba1bd54b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:35:02.922098Z",
     "start_time": "2024-11-07T19:35:02.919096500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def inference(input_ids) -> str:\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        outputs = model.generate(input_ids=torch.tensor(input_ids), num_beams=10, max_length=128)\n",
    "    output = tokenizer.decode(token_ids=outputs[0][1:], skip_special_tokens=True) # for some reason the beginning of sentence token doesn't get removed properly so we cut it off manually\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c770c31-721f-45ce-9ea6-c6463b53cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical_to_human_readable(canonical_form, table_header):\n",
    "    \"\"\"\n",
    "    Convert canonical SQL form to a human-readable SQL string.\n",
    "\n",
    "    :param canonical_form: The canonical form containing \"sel\", \"agg\", and \"conds\".\n",
    "    :param agg_mapping: Dictionary mapping aggregation names to IDs.\n",
    "    :param cond_mapping: Dictionary mapping condition operators to IDs.\n",
    "    :return: Human-readable SQL query string.\n",
    "    \"\"\"\n",
    "    agg_mapping = {\n",
    "        \"\": 0,\n",
    "        \"MAX\": 1,\n",
    "        \"MIN\": 2,\n",
    "        \"COUNT\": 3,\n",
    "        \"SUM\": 4,\n",
    "        \"AVG\": 5\n",
    "    }\n",
    "\n",
    "    cond_mapping = {'=': 0, '>': 1, '<': 2}\n",
    "    # Reverse the mappings for easier lookup\n",
    "    rev_agg_mapping = {v: k for k, v in agg_mapping.items()}\n",
    "    rev_cond_mapping = {v: k for k, v in cond_mapping.items()}\n",
    "\n",
    "    # Extract the selected column and aggregation type\n",
    "    selected_column = table_header[canonical_form[\"sel\"]]\n",
    "    aggregation = rev_agg_mapping.get(canonical_form[\"agg\"], \"\")\n",
    "\n",
    "    # Formulate the SELECT clause\n",
    "    if aggregation:\n",
    "        select_clause = f\"SELECT {aggregation}({selected_column})\"\n",
    "    else:\n",
    "        select_clause = f\"SELECT {selected_column}\"\n",
    "\n",
    "    # Process conditions\n",
    "    conditions = []\n",
    "    for col, op_id, value in canonical_form[\"conds\"]:\n",
    "        operator = rev_cond_mapping.get(op_id, \"=\")\n",
    "        conditions.append(f\"{table_header[col]} {operator} {value}\")\n",
    "\n",
    "    # Formulate the WHERE clause if conditions exist\n",
    "    where_clause = \"\"\n",
    "    if conditions:\n",
    "        where_clause = \" WHERE \" + \" AND \".join(conditions)\n",
    "\n",
    "    # Combine SELECT and WHERE clauses\n",
    "    human_readable_query = select_clause + where_clause\n",
    "\n",
    "    return human_readable_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6b9730-f9e0-4d15-a679-0615ba11c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(query, table_header, reverse_mapping):\n",
    "    cleaned_canonical = parse_sql_to_canonical(query, table_header, reverse_mapping)\n",
    "    cleaned_query = canonical_to_human_readable(cleaned_canonical, table_header)\n",
    "    return cleaned_canonical, cleaned_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c618cf85c52fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T19:35:36.281157900Z",
     "start_time": "2024-11-07T19:35:34.837235100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: SELECT COUNT(Approx premium) WHERE Tariff code = G9\n",
      "Correct query: SELECT Approx premium FROM table WHERE Tariff code = g9\n"
     ]
    }
   ],
   "source": [
    "output = inference(tokenized_sample[\"input_ids\"])\n",
    "pred_canonical, pred_human_readable = post_processing(output, sample[\"table\"][0][\"header\"], reverse_mapping)\n",
    "correct_canonical, correct_human_readable = post_processing(sample[\"sql\"][0][\"human_readable\"], sample[\"table\"][0][\"header\"], reverse_mapping) # I know this line is stupid but I don't have a better way to get the proper canonical form for the solutions. The one in the data is in a weird format not supported by the db_engine\n",
    "print(f\"Model output: {pred_human_readable}\")\n",
    "print(f\"Correct query: {sample[\"sql\"][0][\"human_readable\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e82f564-f302-4bc9-a140-55de992e29b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: {'sel': 3, 'agg': 3, 'conds': {(1, 0, 'G9')}}\n",
      "Correct query: {'sel': 3, 'agg': 0, 'conds': {(1, 0, 'g9')}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model output: {pred_canonical}\")\n",
    "print(f\"Correct query: {correct_canonical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28c5437-8a0b-4ec7-a975-b9f70d650e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result: [1]\n",
      "Correct result: ['4p/min']\n"
     ]
    }
   ],
   "source": [
    "db_path = os.path.abspath(path+'/tables/test/test.db')\n",
    "if not os.path.exists(db_path):\n",
    "    raise FileNotFoundError(f\"Database file not found: {db_path}\")\n",
    "db_engine = DBEngine(db_path)\n",
    "\n",
    "table_id = sample[\"table\"][0][\"id\"]\n",
    "pred_query = Query.from_dict(pred_canonical)\n",
    "correct_query = Query.from_dict(correct_canonical)\n",
    "try:\n",
    "    pred_result = db_engine.execute_query(table_id, pred_query)\n",
    "except Exception as e:\n",
    "    pred_result = f\"Execution error: {e}\"\n",
    "\n",
    "try:\n",
    "    gold_result = db_engine.execute_query(table_id, correct_query)\n",
    "except Exception as e:\n",
    "    gold_result = f\"Execution error: {e}\"\n",
    "\n",
    "print(f\"Query result: {pred_result}\")\n",
    "print(f\"Correct result: {gold_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07cd5a5-6ca4-486f-9306-9ab87699e260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1daa984-9ee9-4c78-bc99-b531a51c58c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
