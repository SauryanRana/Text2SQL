{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:32:55.690514900Z",
     "start_time": "2024-11-27T09:32:50.319130500Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoConfig, AutoTokenizer, T5Tokenizer, Trainer, TrainingArguments, PreTrainedTokenizerFast, Seq2SeqTrainer, Seq2SeqTrainingArguments, convert_slow_tokenizer\n",
    "from utils import filter_function, preprocess_function, encode_rare_chars, tokenize, create_metrics_computer\n",
    "import torch\n",
    "import wandb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9590bfb3d3c2d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:32:56.317876200Z",
     "start_time": "2024-11-27T09:32:55.692515100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified config: T5Config {\n",
      "  \"_name_or_path\": \"google/t5-efficient-tiny\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 64,\n",
      "  \"d_kv\": 32,\n",
      "  \"d_model\": 128,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 4,\n",
      "  \"num_heads\": 4,\n",
      "  \"num_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"google/t5-efficient-tiny\")\n",
    "# print(config)\n",
    "# Modify parameters\n",
    "# config.num_layers = 3  # Set number of encoder layers\n",
    "# config.num_decoder_layers = 3  # Set number of decoder layers\n",
    "config.num_heads = 4  # Set number of attention heads\n",
    "config.d_model = 128  # Set embedding dimension\n",
    "config.d_ff = 64  # Set feed-forward dimension\n",
    "config.d_kv = 32\n",
    "# config.dropout = 0.2\n",
    "\n",
    "# Initialize the model with the modified configuration\n",
    "model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "\n",
    "print(\"Modified config:\", config)\n",
    "\n",
    "# Initialize the model from scratch using the configuration\n",
    "model = AutoModelForSeq2SeqLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1625b671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(512, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/t5-efficient-tiny\")\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=convert_slow_tokenizer.convert_slow_tokenizer(T5Tokenizer(\"tokenizers/sp_512_bpe_encoded.model\", legacy=False, load_from_cache_file=False)))\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "# tokenizer = T5Tokenizer(vocab_file=\"tokenizers/sp_16k_bpe_1.model\", legacy=False, load_from_cache_file=False)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a339dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[268, 51, 137, 79, 166, 127, 8, 345, 13, 356, 40, 12, 127, 322, 106, 21, 160, 306, 46, 341, 356, 345, 352, 55, 340, 372, 3, 337, 74, 3, 335, 54, 3, 344, 208, 3, 338, 374, 342, 43, 354, 346, 2]\n",
      "['How', 'of', 'ten', 'd', 'id', 'g', 'er', 'm', 'an', 'y', 'w', 'in', 'g', 'old', 'in', 'the', '19', '94', 'o', 'l', 'y', 'm', 'p', 'ic', 's', '?', '[SEP]', 'n', 'ame', '[SEP]', 't', 'eam', '[SEP]', 'c', 'ountry', '[SEP]', 'i', 'k', 'h', 'as', 'b', 'd', '</s>']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"How often did germany win gold in the 1994 olympics?[SEP]name[SEP]team[SEP]country[SEP]ikhasbd\")\n",
    "print(tokens)\n",
    "print([tokenizer.decode(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e5f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters in the token embedding layer: 65536\n",
      "Total number of trainable parameters: 986112\n"
     ]
    }
   ],
   "source": [
    "token_embedding = model.shared  # Shared token embedding layer\n",
    "num_token_embedding_params = sum(p.numel() for p in token_embedding.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters in the token embedding layer: {num_token_embedding_params}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa00e3f707b22d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T09:37:21.476273300Z",
     "start_time": "2024-11-27T09:36:35.118770100Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '../datasets/wikisql'\n",
    "dataset = load_dataset(path+'/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec7430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = dataset.map(preprocess_function, batched=True, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f24976f-84d7-4685-be17-c03b2a3bb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file_path = 'mapping.json'\n",
    "reverse_mapping_file_path = 'reverse_mapping.json'\n",
    "\n",
    "with open(mapping_file_path, 'r', encoding='utf-8') as mapping_file:\n",
    "    mapping = json.load(mapping_file)\n",
    "\n",
    "with open(reverse_mapping_file_path, 'r', encoding='utf-8') as reverse_mapping_file:\n",
    "    reverse_mapping = json.load(reverse_mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c68056-3522-4e4e-ad61-ad8402896e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = preprocessed_dataset.map(lambda batch: encode_rare_chars(batch, mapping), batched=True, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ccf3b77-ef21-4059-bb7f-f10bc7a53da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = preprocessed_dataset.map(lambda batch: tokenize(batch, tokenizer), batched=True, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35235f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['phase', 'question', 'table', 'sql', 'input_text', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 56355\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = tokenized_dataset[\"train\"]\n",
    "val_data = tokenized_dataset[\"validation\"]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae99d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.filter(lambda sample: filter_function(sample, tokenizer), batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7090be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(project, experiment_name, lr=2e-4, batch_size=128):\n",
    "    seeds = [1337] # [1337, 69, 42]\n",
    "    compute_metrics = create_metrics_computer(val_data, tokenizer, path+'/tables/validation/dev.db', reverse_mapping)\n",
    "    full_metrics = []\n",
    "    for run in range(len(seeds)):\n",
    "        model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        run_name = experiment_name + \"_\" + str(run+1)\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=\"./results/\"+run_name,\n",
    "            run_name=run_name,\n",
    "            report_to=\"wandb\",\n",
    "            save_strategy=\"epoch\",\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            eval_strategy=\"epoch\",\n",
    "            num_train_epochs=50,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=256,\n",
    "            learning_rate=lr,\n",
    "            # weight_decay=experiment[3],\n",
    "            predict_with_generate=True,\n",
    "            generation_max_length=64,\n",
    "            generation_num_beams=5,\n",
    "            seed=seeds[run],\n",
    "            optim=\"lion_32bit\",\n",
    "            # adam_beta2=0.99,\n",
    "            lr_scheduler_type=\"constant\"\n",
    "            # warmup_steps=(56355//batch_size+1)*4,\n",
    "            # lr_scheduler_kwargs={\"num_cycles\": 3}\n",
    "        )\n",
    "\n",
    "        # Trainer\n",
    "        trainer = Seq2SeqTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_data,\n",
    "            eval_dataset=val_data.shuffle(seed=42).select(range(500)), # evaluation is slow, do it on subset\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        wandb.init(project=project, group=experiment_name, name=run_name)\n",
    "        trainer.train()\n",
    "        # Evaluate on the full dataset after training\n",
    "        full_metrics.append(trainer.evaluate(eval_dataset=val_data))\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "976a5c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: bruno-heberle (afy_shk). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Bruno\\Projects\\Text2SQL\\src\\wandb\\run-20250128_164346-8vkc38ve</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/afy_shk/ablation-studies2/runs/8vkc38ve' target=\"_blank\">4_heads_2e-4_lr_constant_512MappingTokenizer_128_bs_64_dff_32_kv_128d_1</a></strong> to <a href='https://wandb.ai/afy_shk/ablation-studies2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/afy_shk/ablation-studies2' target=\"_blank\">https://wandb.ai/afy_shk/ablation-studies2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/afy_shk/ablation-studies2/runs/8vkc38ve' target=\"_blank\">https://wandb.ai/afy_shk/ablation-studies2/runs/8vkc38ve</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22050' max='22050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22050/22050 56:59, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Sel Accuracy</th>\n",
       "      <th>Agg Accuracy</th>\n",
       "      <th>Conds Accuracy</th>\n",
       "      <th>Execution Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.265791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.666700</td>\n",
       "      <td>1.003437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.215600</td>\n",
       "      <td>0.840438</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.007000</td>\n",
       "      <td>0.732142</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.881700</td>\n",
       "      <td>0.653053</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.742000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.795400</td>\n",
       "      <td>0.598671</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.729600</td>\n",
       "      <td>0.552970</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.510354</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.470452</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.429132</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.392649</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.532700</td>\n",
       "      <td>0.351106</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.313758</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.279349</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.236096</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.339800</td>\n",
       "      <td>0.191965</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.339800</td>\n",
       "      <td>0.146309</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.099861</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.087215</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.071992</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.068381</td>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.064957</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.062376</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.059478</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.057021</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.055596</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.054908</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.055123</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.053410</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.051804</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.050588</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.050162</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.049560</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.047624</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.048002</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.046919</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.046417</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.046833</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.045338</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.044536</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.044779</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.044363</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 08:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/agg_accuracy</td><td>▁▃▄▅▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>eval/conds_accuracy</td><td>▁▁▁▂▂▂▂▂▂▃▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>eval/execution_accuracy</td><td>▁▁▁▁▁▂▂▂▂▃▄▄▅▅▆▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>eval/loss</td><td>█▆▅▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/overall_accuracy</td><td>▁▁▁▁▁▂▂▂▃▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▄▇▃▃▄▆▆▅▆█▅▁▃▁▄▇▅▆▇█▆▆▇▇▅▇▆█▇█▇▆▇█▇▂▇▆▂▅</td></tr><tr><td>eval/sel_accuracy</td><td>▁▁▂▂▃▃▄▄▅▆▆▆▇▇▇▇█▇▇█████████████████████</td></tr><tr><td>eval/steps_per_second</td><td>▆█▃▃▃▆▆▆██▆▁▁▆▆▆████▆▆██▆█▆█████▆██▃█▆▃▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>██▇█▇▇▇▇▆▆▇▇▅▆▃▄▃▃▂▂▂▁▁▁▁▂▁▁▂▁▁▂▂▁▁▁▁▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/agg_accuracy</td><td>0.89799</td></tr><tr><td>eval/conds_accuracy</td><td>0.74599</td></tr><tr><td>eval/execution_accuracy</td><td>0.53462</td></tr><tr><td>eval/loss</td><td>0.04268</td></tr><tr><td>eval/overall_accuracy</td><td>0.64434</td></tr><tr><td>eval/runtime</td><td>525.7207</td></tr><tr><td>eval/samples_per_second</td><td>16.018</td></tr><tr><td>eval/sel_accuracy</td><td>0.93267</td></tr><tr><td>eval/steps_per_second</td><td>0.063</td></tr><tr><td>total_flos</td><td>1991601930240000.0</td></tr><tr><td>train/epoch</td><td>50</td></tr><tr><td>train/global_step</td><td>22050</td></tr><tr><td>train/grad_norm</td><td>0.06446</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>0.0454</td></tr><tr><td>train_loss</td><td>0.29268</td></tr><tr><td>train_runtime</td><td>3419.6578</td></tr><tr><td>train_samples_per_second</td><td>823.986</td></tr><tr><td>train_steps_per_second</td><td>6.448</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">4_heads_2e-4_lr_constant_512MappingTokenizer_128_bs_64_dff_32_kv_128d_1</strong> at: <a href='https://wandb.ai/afy_shk/ablation-studies2/runs/8vkc38ve' target=\"_blank\">https://wandb.ai/afy_shk/ablation-studies2/runs/8vkc38ve</a><br> View project at: <a href='https://wandb.ai/afy_shk/ablation-studies2' target=\"_blank\">https://wandb.ai/afy_shk/ablation-studies2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250128_164346-8vkc38ve\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment(\"ablation-studies2\", \"4_heads_2e-4_lr_constant_512MappingTokenizer_128_bs_64_dff_32_kv_128d\", 2e-4) # \"cosine_with_restarts_and_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba00d3-a363-41e0-9bad-d9157b9feffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 0, -1):\n",
    "    factor = 2**i\n",
    "    lr = 1e-4 * factor**0.5\n",
    "    batch_size = round(32 * factor)\n",
    "    print(lr, batch_size)\n",
    "    experiment(\"ablation-studies2\", f\"2_heads_{lr:.3e}_lr_constant_512MappingTokenizer_{batch_size}_bs_redo2\", lr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27b314-b184-4838-8d86-f547cf673479",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics = create_metrics_computer(val_data, tokenizer, path+'/tables/validation/dev.db', reverse_mapping)\n",
    "samples = 56355\n",
    "for i in range(3, 0, -1):\n",
    "    factor = 2**i\n",
    "    lr = 1e-4 * factor**0.5\n",
    "    batch_size = round(32 * factor)\n",
    "    batches_per_epoch = int(samples/batch_size)+1\n",
    "    total_batches = batches_per_epoch*25\n",
    "    run_name = f\"2_heads_{lr:.3e}_lr_constant_512MappingTokenizer_{batch_size}_bs_1\"\n",
    "    checkpoint = f\"./results/{run_name}/checkpoint-{total_batches}\"\n",
    "    model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=\"./results/\"+run_name,\n",
    "            run_name=run_name,\n",
    "            report_to=\"wandb\",\n",
    "            save_strategy=\"epoch\",\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            eval_strategy=\"epoch\",\n",
    "            num_train_epochs=50,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=256,\n",
    "            learning_rate=lr,\n",
    "            # weight_decay=experiment[3],\n",
    "            predict_with_generate=True,\n",
    "            generation_max_length=64,\n",
    "            generation_num_beams=5,\n",
    "            seed=1337,\n",
    "            optim=\"lion_32bit\",\n",
    "            # adam_beta2=0.99,\n",
    "            lr_scheduler_type=\"constant\"\n",
    "            # warmup_steps=(56355//batch_size+1)*4,\n",
    "            # lr_scheduler_kwargs={\"num_cycles\": 3}\n",
    "        )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,                     # Your model instance\n",
    "        args=training_args,              # Training arguments\n",
    "        train_dataset=train_data,        # Your training dataset\n",
    "        eval_dataset=val_data.shuffle(seed=42).select(range(500)), # evaluation is slow, do it on subset\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Resume training from the checkpoint\n",
    "    trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    trainer.evaluate(eval_dataset=val_data)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_metrics = {key: sum(run[key] for run in full_metrics) / len(full_metrics) for key in full_metrics[0]}\n",
    "average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log or update the summary table\n",
    "def update_results_table(experiment_name, metrics):\n",
    "    artifact_name = \"experiment_results\"\n",
    "    try:\n",
    "        artifact = wandb.Api().artifact(project_name + \"/\" + artifact_name + \":latest\")\n",
    "        artifact_table = artifact.get(\"results_table\")\n",
    "    except:\n",
    "        # If no artifact exists yet, start a new table\n",
    "        artifact = wandb.Artifact(artifact_name, type=\"results_summary\")\n",
    "        artifact_table = wandb.Table(columns=[\"Experiment\"] + list(metrics.keys()))\n",
    "    \n",
    "    # Unpack the metrics dictionary values as a row\n",
    "    artifact_table.add_data(experiment_name, *[metrics[key] for key in metrics])\n",
    "    \n",
    "    # Create a new artifact with the updated table    \n",
    "    artifact.add(artifact_table, \"results_table\", overwrite=True)\n",
    "    \n",
    "    # Log the updated artifact\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "update_results_table(experiment_name, average_metrics)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d98a0f70712780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually validate model\n",
    "input_ids = tokenized_val_data[\"input_ids\"]\n",
    "labels = tokenized_val_data[\"labels\"]\n",
    "\n",
    "# Run the model to generate predictions\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    predictions = model.generate(input_ids=torch.tensor(input_ids).to(torch.device(\"cuda\")))\n",
    "\n",
    "print(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions and labels\n",
    "input_text = [tokenizer.decode(inputs, skip_special_tokens=True) for inputs in input_ids]\n",
    "predictions_text = [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]\n",
    "labels_text = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
    "print(input_text)\n",
    "print(predictions_text)\n",
    "print(labels_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"ablation-studies\", name=\"predictions_table\")\n",
    "# Initialize the wandb.Table\n",
    "table = wandb.Table(columns=[\"Input\", \"Prediction\", \"Correct Output\", \"Match\"])\n",
    "\n",
    "# Add rows to the table\n",
    "for inp, pred, correct in zip(input_text, predictions_text, labels_text):\n",
    "    match = pred == correct\n",
    "    print(f\"Adding row: {idx}, {pred}, {correct}, {match}\")  # Debugging\n",
    "    table.add_data(inp, pred, correct, match)\n",
    "\n",
    "# Log the table\n",
    "wandb.log({\"Predictions Table\": table})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceccbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'results/lion_32bit_bs16_3/checkpoint-3523'\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20dfac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\" + checkpoint_dir + \"/eval\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=25,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=512,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=48,\n",
    "    generation_num_beams=5,\n",
    "    optim=\"lion_32bit\"\n",
    ")\n",
    "\n",
    "compute_metrics = create_metrics_computer(tokenized_val_data, tokenizer, path+'/tables/validation/dev.db')\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_data,\n",
    "    eval_dataset=tokenized_val_data,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec99333",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6431d-1634-4b3e-aa37-a667a6e3ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"hello\": \"world\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba00f59-6489-466a-9531-ec370f954712",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, -3, -1):\n",
    "    print(2**i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75400111-012a-46e7-b04e-6a489c345363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
